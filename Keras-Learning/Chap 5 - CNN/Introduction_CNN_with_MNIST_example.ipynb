{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong chapter này, ta sẽ học về convolutional neural networks ( hay còn gọi là convnets, hoặc CNN) - một dạng deep learning được sử dụng hầu hết trong mảng computer vision. Ta sẽ học cách áp dụng chúng cho bài toán classify ảnh, đặc biệt với data set nhỏ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong chương này, ta sẽ trả lời các câu hỏi sau:\n",
    "- Convnets là gì ?\n",
    "- Model convnets học như thế nào ?\n",
    "- convolution và maxpooling là gì ?\n",
    "\n",
    "Sau đó ta sẽ bao quát bài toán classify ảnh với data set nhỏ :\n",
    "- Tự xây dựng và train 1 mạng convnets nhỏ \n",
    "- Sử dụng data augmentation (các phép biến đổi để tạo thêm data) giúp giảm bớt over-fitting\n",
    "- Fine-tuning 1 model đã train trước đó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 GIỚI THIỆU VỀ CONVNETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ tìm hiểu lý do tại sao convnets rất hay được sử dụng trong các bài toán computer vision. Nhưng đầu tiên ta sẽ thực hành với 1 ví dụ cơ bản về convnet : Dùng convnets để classify MNIST - dataset ta đã từng giải ở chapter 2 với Dense layer (acc ~97.8%).\n",
    "\n",
    "Spoiler warning :Dù convnets model rất cơ bản, độ chính xác vẫn cao hơn Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model convnets là một khối các layer Conv2D và MaxPooling2D. Quan trọng hơn, Convnet nhận vào 2D tensor với shape (image_height,image_width,image_channels) ( chưa kể batch ). Trong bài toán này, ta sẽ config input với size (28,28,1) : format của MNIST sample bằng cách pass input_shape=(28,28,1) vào layer đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dễ thấy output của mỗi Conv2D và MaxPooling2D layer là 2D tensor với **shape (h,w,channels)**. w và h càng **giảm dần** khi **xuống các layer dưới**, trong khi **channels** ( số kênh ) được kiểm soát = **số đầu tiên pass vào Conv2D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước tiếp theo ta sẽ feed tensor ( với shape (3,3,64)) vào 1 dense layer. Nhưng vì layer này chỉ nhận vector ( 1D ), ta sẽ sử dụng Flatten() layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten()) # Model sẽ có shape (None,3*3*64) -> vector\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta sẽ train convnet trên tập MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# reshape có thêm 1 thể hiện số kênh màu (1)\n",
    "train_images = train_images.reshape((60000,28,28,1))\n",
    "train_images = train_images.astype('float32') /255\n",
    "\n",
    "test_images = test_images.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 25s - loss: 0.1794 - acc: 0.9429    \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0476 - acc: 0.9857    \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0322 - acc: 0.9902    \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0245 - acc: 0.9928    \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0185 - acc: 0.9943    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3f4c927f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_images,train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99039999999999995"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model :\n",
    "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quào, 99%,  network với nhiều Dense layer ở bài 2 chỉ được 97% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tại sao Convnet hoạt động quá tốt so với model sử dụng tất cả Dense layer ??? Để trả lời câu hỏi này, ta sẽ nghiên cứu Conv2D và MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
